{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folders:\n",
    "folder_datafiles = '/mbshome/nvelthuijs/Cofactors/20200402_Transcriptionregulationlist/Datafiles/'\n",
    "folder_corrected_names = '/mbshome/nvelthuijs/Cofactors/20200402_Transcriptionregulationlist/Datafiles_corrected_names/'\n",
    "folder_output = '/mbshome/nvelthuijs/Cofactors/20200402_Transcriptionregulationlist/Output_files/'\n",
    "\n",
    "# Files:\n",
    "selected_bp_file = folder_datafiles + 'selected_GO_terms_bp.txt'\n",
    "selected_mf_file = folder_datafiles + 'selected_GO_terms_mf.txt'\n",
    "selected_cc_file = folder_datafiles + 'selected_GO_terms_cc.txt'\n",
    "annotations_file = folder_corrected_names + 'goa_human_corrected_names.txt'\n",
    "coregulators_file = folder_datafiles + 'gocofs.txt'\n",
    "go_full_file = folder_datafiles + 'go_full.txt'\n",
    "coregulators_list1 = folder_output + '06_Transcription_regulatorlist_baitset1_without_scores.csv'\n",
    "coregulators_list2 = folder_output + '07_Transcription_regulatorlist_baitset2_without_scores.csv'\n",
    "coregulators_list3 = folder_output + '08_Transcription_regulatorlist_baitset3_without_scores.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of selected GO-terms: 478\n",
      "Number of coregulators: 440\n",
      "Missed terms in full GO:\n",
      "\t GO:0001158 0\n",
      "\t GO:0090568 0\n",
      "\t GO:0044798 0\n",
      "\t GO:0001012 0\n",
      "\t GO:0035389 0\n",
      "\t GO:0030702 0\n",
      "\t GO:1902368 0\n",
      "\t GO:0035390 0\n",
      "\t GO:0000980 0\n",
      "\t GO:0044213 0\n",
      "\t GO:1990141 0\n",
      "\t GO:0070870 0\n",
      "\t GO:1904497 0\n",
      "\t GO:0001047 0\n",
      "\t GO:0099114 0\n",
      "\t GO:0070869 0\n",
      "\t GO:0070924 0\n",
      "\t GO:0006344 0\n",
      "\t GO:0044212 0\n",
      "\t GO:0035326 0\n",
      "\t GO:1990152 0\n",
      "\t GO:0006343 0\n"
     ]
    }
   ],
   "source": [
    "# Calculate weight of selected GO-terms:\n",
    "\n",
    "# Create set of all selected GO terms:\n",
    "selected_terms = set()\n",
    "with open(selected_bp_file) as selected_bp, open(selected_mf_file) as selected_mf, open(selected_cc_file) as selected_cc:\n",
    "    files = [selected_bp, selected_mf, selected_cc]\n",
    "    for file in files:\n",
    "        for line in file:\n",
    "            selected_terms.add(line.strip())\n",
    "print('Number of selected GO-terms:', len(selected_terms))\n",
    "\n",
    "# Create set of coregulators:\n",
    "with open(coregulators_file) as coregulators:\n",
    "    coregs = set()\n",
    "    for line in coregulators:\n",
    "        coregs.add(line.strip())\n",
    "coregs_number = len(coregs)\n",
    "print('Number of coregulators:', coregs_number)\n",
    "\n",
    "# Read file with annotations into dataframe,\n",
    "# select rows with a selected annotations\n",
    "# to a coregulator:\n",
    "with open(annotations_file) as annotations:\n",
    "    annotations_df = pd.read_table(annotations, sep = '\\t', skiprows = 38, header = None, usecols = [2, 4])\n",
    "annotations_df.columns = ['Protein', 'GO-term']\n",
    "annotations_selected_coregs_df = annotations_df.loc[annotations_df['Protein'].isin(coregs) & annotations_df['GO-term'].isin(selected_terms)].drop_duplicates().copy()\n",
    "\n",
    "# Create dictionary where every selected GO-term\n",
    "# is a key, which value is a tuple of\n",
    "# (number of times used on a coregulator, weight):\n",
    "counts_dict = {}\n",
    "terms_annotations = list(annotations_selected_coregs_df['GO-term'])\n",
    "for term in selected_terms:\n",
    "    count = terms_annotations.count(term)\n",
    "    counts_dict[term] = (count, count / (coregs_number * 2) + 0.5)\n",
    "    \n",
    "# Create dictionary where every GO-term is a key,\n",
    "# which value is a tuple of (term name, namespace):\n",
    "term_definitions = {}\n",
    "with open(go_full_file) as go_full:\n",
    "    for line in go_full:\n",
    "        if line.startswith('id:'):\n",
    "            last_id = line.strip()\n",
    "        elif line.startswith('name:'):\n",
    "            last_name = line.strip()\n",
    "        elif line.startswith('namespace:'):\n",
    "            last_namespace = line.strip()\n",
    "            term_definitions[last_id[4:]] = (last_name[6:], last_namespace[11:])\n",
    "        elif line.startswith('[Typedef]'):\n",
    "            break\n",
    "            \n",
    "# Write weight of selected terms to a file:\n",
    "print('Missed terms in full GO:')\n",
    "\n",
    "with open(folder_output + '09_Selected_terms_weight.tab', 'w') as outfile:\n",
    "    for term in counts_dict.keys():\n",
    "        count = str(counts_dict[term][0])\n",
    "        weight = str(counts_dict[term][1])\n",
    "        if term in term_definitions.keys():\n",
    "            aspect = term_definitions[term][1]\n",
    "            definition = term_definitions[term][0]\n",
    "        else:\n",
    "            aspect = 'ERROR'\n",
    "            definition = 'ERROR'\n",
    "            print('\\t', term, count)\n",
    "        newline = '\\t'.join([term, count, weight, aspect, definition])\n",
    "        outfile.write(newline + '\\n')\n",
    "\n",
    "# Create sets of selected GO-terms for each aspect:\n",
    "with open(folder_output + '09_Selected_terms_weight.tab') as selected_terms_file:\n",
    "    selected_cc = set()\n",
    "    selected_mf = set()\n",
    "    selected_bp = set()\n",
    "    for line in selected_terms_file:\n",
    "        line = line.strip().split('\\t')\n",
    "        term = line[0]\n",
    "        namespace = line[3]\n",
    "        if namespace == 'biological_process':\n",
    "            selected_bp.add(term)\n",
    "        elif namespace == 'cellular_component':\n",
    "            selected_cc.add(term)\n",
    "        elif namespace == 'molecular_function':\n",
    "            selected_mf.add(term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_branch(branch, df):\n",
    "    \"\"\"\n",
    "    Takes the GO-df and the branch ('F', 'C', or 'P') and\n",
    "    returns a df with only annotations in that branch.\n",
    "    \"\"\"\n",
    "    return df.loc[df['Branch'] == branch].drop(columns = ['Branch']).copy().reset_index(drop = True)\n",
    "\n",
    "def go_dict(df):\n",
    "    out_dict = {}\n",
    "    for index, row in df.iterrows():\n",
    "        uniprot_id, gene_symbol, term = (row[i] for i in range(3))\n",
    "        if not uniprot_id in out_dict.keys():\n",
    "            out_dict[uniprot_id] = {term}\n",
    "        else:\n",
    "            out_dict[uniprot_id].add(term)\n",
    "    return out_dict\n",
    "\n",
    "go_df = pd.read_table(annotations_file,\n",
    "                      skiprows = 38,\n",
    "                      header = None,\n",
    "                      usecols = [1, 2, 8, 4]).rename(columns = {1:'UniProtID',\n",
    "                                                                2:'Gene Symbol',\n",
    "                                                                4:'GO-term',\n",
    "                                                                8:'Branch'})\n",
    "\n",
    "go_cc, go_mf, go_bp = (select_branch(x, go_df) for x in ['C', 'F', 'P'])\n",
    "cc_dict, mf_dict, bp_dict = (go_dict(x) for x in [go_cc, go_mf, go_bp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "def go_terms(id_list, go_dict):\n",
    "    \"\"\"\n",
    "    Takes the UniProt ID column (as a list) and the dictionary translating\n",
    "    IDs to corresponding GO terms. Returns a list that can be used a new\n",
    "    column in the dataframe containing all GO-terms annotated to that protein.\n",
    "    \"\"\"\n",
    "    return [go_dict[x] if x in go_dict.keys() else np.nan for x in id_list]\n",
    "\n",
    "def go_terms_hits(all_terms_column, go_interesting):\n",
    "    \"\"\"\n",
    "    Takes a column containing sets of GO-terms and returns a\n",
    "    list that can be used as a new column containing the GO-terms that are\n",
    "    in the interesting GO terms set.\n",
    "    \"\"\"\n",
    "    all_terms_column = list(all_terms_column)\n",
    "    interesting_annotations_column = []\n",
    "    for annotations in all_terms_column:\n",
    "        newset = set()\n",
    "        if isinstance(annotations, set):\n",
    "            for annotation in annotations:\n",
    "                if annotation in go_interesting:\n",
    "                    newset.add(annotation)\n",
    "        if len(newset) == 0:\n",
    "            interesting_annotations_column.append(np.nan)\n",
    "        else:\n",
    "            interesting_annotations_column.append(newset)\n",
    "    return interesting_annotations_column\n",
    "\n",
    "def interesting_go_counts(df, go_interesting, branch):\n",
    "    \"\"\"\n",
    "    \n",
    "    branch = 'MF', 'CC' or 'BP'.\n",
    "    \"\"\"\n",
    "    hits_col = []\n",
    "    tot_ann_col = []\n",
    "    fraction_col = []\n",
    "    for index, row in list_df.iterrows():\n",
    "        gos = row['{} terms'.format(branch)]\n",
    "        hits = 0\n",
    "        if isinstance(gos, set):\n",
    "            annots = len(gos)\n",
    "            for term in gos:\n",
    "                if term in go_interesting:\n",
    "                    hits += 1\n",
    "        else:\n",
    "            annots = 0\n",
    "        hits_col.append(hits)\n",
    "        tot_ann_col.append(annots)\n",
    "        if annots > 0:\n",
    "            fraction_col.append(hits/annots)\n",
    "        else:\n",
    "            fraction_col.append(np.nan)\n",
    "    outdf = pd.DataFrame({\n",
    "        '{} selected terms number'.format(branch) : hits_col,\n",
    "        '{} total annotations'.format(branch) : tot_ann_col\n",
    "    })\n",
    "    return pd.concat([df, outdf], axis = 1)\n",
    "\n",
    "def domain_scores_col(df, weightdict, branch):\n",
    "    new_col_pos = []\n",
    "    new_col_neg = []\n",
    "    for index, row in df.iterrows():\n",
    "        terms = row['{} selected terms'.format(branch)]\n",
    "        total = row['{} total annotations'.format(branch)]\n",
    "        if isinstance(terms, set):\n",
    "            neg_score = 0\n",
    "            all_weights = [weightdict[x][1] for x in terms]\n",
    "            if len(all_weights) <= 5:\n",
    "                weightsum = sum(all_weights)\n",
    "            else:\n",
    "                all_weights.sort(reverse=True)\n",
    "                weightsum = sum(all_weights[:5])\n",
    "        else:\n",
    "            weightsum = 0\n",
    "            if total > 5:\n",
    "                neg_score = -5\n",
    "            else:\n",
    "                neg_score = -total\n",
    "        new_col_pos.append(weightsum)\n",
    "        new_col_neg.append(neg_score)\n",
    "    df['{} GO score'.format(branch)] = new_col_pos\n",
    "    df['{} GO score penalty'.format(branch)] = new_col_neg\n",
    "    return df\n",
    "\n",
    "def domainsums(df):\n",
    "    new_col_pos = []\n",
    "    new_col_neg = []\n",
    "    new_col_total = []\n",
    "    for index, row in df.iterrows():\n",
    "        pos_scores = [row['{} GO score'.format(x)] for x in ['CC', 'BP', 'MF']]\n",
    "        neg_scores = [row['{} GO score penalty'.format(x)] for x in ['CC', 'BP', 'MF']]\n",
    "        sumscore_pos = sum(pos_scores)\n",
    "        sumscore_neg = sum(neg_scores)\n",
    "        new_col_pos.append(sumscore_pos)\n",
    "        new_col_neg.append(sumscore_neg)\n",
    "        new_col_total.append((sumscore_pos + sumscore_neg) / 3)\n",
    "    df['Total GO score'] = new_col_pos\n",
    "    df['Total GO score penalty'] = new_col_neg\n",
    "    df['GO score'] = new_col_total\n",
    "    return df\n",
    "\n",
    "def mine_score(df):\n",
    "    in_humap = df['ComplexID_huMAP'].notnull().astype('int')\n",
    "    in_corum = df['ComplexID_CORUM'].notnull().astype('int')\n",
    "    in_biogrid = df['Interaction_TF_BioGRID']\n",
    "    in_intact = df['Interaction_TF_IntACT']\n",
    "    in_bait = (df['In_bait_crems'] |\n",
    "               df['In_bait_snfs'] |\n",
    "               df['In_bait_nursa'] |\n",
    "               df['In_bait_gocofs'] |\n",
    "               df['In_NVS'])\n",
    "\n",
    "    score = (in_humap +\n",
    "             in_corum +\n",
    "             in_biogrid +\n",
    "             in_intact +\n",
    "             in_bait)\n",
    "    \n",
    "    df['Mine score'] = score\n",
    "    return df\n",
    "\n",
    "for coregulator_list_file, name in zip([coregulators_list1, coregulators_list2, coregulators_list3],\n",
    "                                       ['10_Transcription_regulatorlist_baitset1_with_scores.csv',\n",
    "                                        '11_Transcription_regulatorlist_baitset2_with_scores.csv',\n",
    "                                        '12_Transcription_regulatorlist_baitset3_with_scores.csv']):\n",
    "    with open(coregulator_list_file) as coregulatorlist:\n",
    "        list_df = pd.read_csv(coregulatorlist)\n",
    "\n",
    "    unips = list(list_df['UniProt ID'])\n",
    "    list_df['CC terms'] = go_terms(unips, cc_dict)\n",
    "    list_df['BP terms'] = go_terms(unips, bp_dict)\n",
    "    list_df['MF terms'] = go_terms(unips, mf_dict)\n",
    "\n",
    "    list_df['CC selected terms'] = go_terms_hits(list_df['CC terms'], selected_cc)\n",
    "    list_df['BP selected terms'] = go_terms_hits(list_df['BP terms'], selected_bp)\n",
    "    list_df['MF selected terms'] = go_terms_hits(list_df['MF terms'], selected_mf)\n",
    "\n",
    "    list_df = interesting_go_counts(list_df, selected_cc, 'CC')\n",
    "    list_df = interesting_go_counts(list_df, selected_bp, 'BP')\n",
    "    list_df = interesting_go_counts(list_df, selected_mf, 'MF')\n",
    "\n",
    "    for x in ['CC', 'BP', 'MF']:\n",
    "        list_df = domain_scores_col(list_df, counts_dict, x)\n",
    "    list_df = domainsums(list_df)\n",
    "\n",
    "    list_df = mine_score(list_df)\n",
    "\n",
    "    list_df['Final score'] = list_df['GO score'] + list_df['Mine score']\n",
    "\n",
    "    list_df.to_csv(folder_output + name, index = False)\n",
    "\n",
    "print('DONE!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
